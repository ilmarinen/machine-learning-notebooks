{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # self.fc1 = nn.Linear(64*64, 192)\n",
    "        self.conv1 = nn.Conv2d(1, 18, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc2 = nn.Linear(18*64*64, 192)\n",
    "        self.fc3 = nn.Linear(192, 192)\n",
    "        self.fc4 = nn.Linear(192, 192)\n",
    "        self.fc5 = nn.Linear(192, 192)\n",
    "        self.fc6 = nn.Linear(192, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, 18*64*64)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        \n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"datasets/sign-language/X.npy\")\n",
    "Y = np.load(\"datasets/sign-language/Y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "indices = list(range(2062))\n",
    "random.shuffle(indices)\n",
    "train_indices = indices[:int(0.8 * 2062)]\n",
    "test_indices = indices[int(0.8 * 2062):]\n",
    "\n",
    "X_train = [X[i] for i in train_indices]\n",
    "Y_train = [int(torch.argmax(torch.tensor(Y[i]))) for i in train_indices]\n",
    "X_test = [X[i] for i in test_indices]\n",
    "Y_test = [int(torch.argmax(torch.tensor(Y[i]))) for i in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train).float().to(device)\n",
    "Y_train = torch.tensor(Y_train).to(device)\n",
    "X_test = torch.tensor(X_test).float().to(device)\n",
    "Y_test = torch.tensor(Y_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0938, 0.1024, 0.0921, 0.0971, 0.1087, 0.1017, 0.0932, 0.1053, 0.1023,\n",
       "         0.1035]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X_train[0].view(1, 1, 64, 64))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8449, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7339, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7128, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6873, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1587, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1556, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1510, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam([net.conv1.weight, net.fc2.weight, net.fc3.weight, net.fc4.weight, net.fc5.weight, net.fc6.weight], lr=0.001)\n",
    "X_train = X_train\n",
    "Y_train = Y_train\n",
    "\n",
    "for i in range(500):\n",
    "    net.zero_grad()\n",
    "    output = net(X_train.view(len(train_indices), 1, 64, 64))\n",
    "    loss = F.cross_entropy(output, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test = net(X_test.view(len(test_indices), 1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31476997578692495\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "for i, out_t in enumerate(output_test):\n",
    "    if int(torch.argmax(out_t)) - int(Y_test[i]) == 0:\n",
    "        correct = correct + 1\n",
    "    total = total + 1\n",
    "\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
