{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # self.fc1 = nn.Linear(64*64, 192)\n",
    "        self.conv1 = nn.Conv2d(1, 18, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc2 = nn.Linear(18*64*64, 192)\n",
    "        self.fc3 = nn.Linear(192, 192)\n",
    "        self.fc4 = nn.Linear(192, 192)\n",
    "        self.fc5 = nn.Linear(192, 192)\n",
    "        self.fc6 = nn.Linear(192, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, 18*64*64)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        \n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"datasets/sign-language/X.npy\")\n",
    "Y = np.load(\"datasets/sign-language/Y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "indices = list(range(2062))\n",
    "random.shuffle(indices)\n",
    "train_indices = indices[:int(0.8 * 2062)]\n",
    "test_indices = indices[int(0.8 * 2062):]\n",
    "\n",
    "X_train = [X[i] for i in train_indices]\n",
    "Y_train = [int(torch.argmax(torch.tensor(Y[i]))) for i in train_indices]\n",
    "X_test = [X[i] for i in test_indices]\n",
    "Y_test = [int(torch.argmax(torch.tensor(Y[i]))) for i in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train).float().to(device)\n",
    "Y_train = torch.tensor(Y_train).to(device)\n",
    "X_test = torch.tensor(X_test).float().to(device)\n",
    "Y_test = torch.tensor(Y_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0981, 0.0942, 0.1017, 0.1062, 0.1010, 0.1010, 0.0917, 0.1037, 0.1033,\n",
       "         0.0990]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X_train[0].view(1, 1, 64, 64))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3023, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0587, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7339, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6959, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6756, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6676, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1605, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam([net.conv1.weight, net.fc2.weight, net.fc3.weight, net.fc4.weight, net.fc5.weight, net.fc6.weight], lr=0.001)\n",
    "X_train = X_train\n",
    "Y_train = Y_train\n",
    "\n",
    "for i in range(500):\n",
    "    net.zero_grad()\n",
    "    output = net(X_train.view(len(train_indices), 1, 64, 64))\n",
    "    loss = F.cross_entropy(output, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
